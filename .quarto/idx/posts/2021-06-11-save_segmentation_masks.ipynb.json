{"title":"Export Segmentation Masks","markdown":{"yaml":{"aliases":["/Pytorch/fastai/cv/2021/06/11/save_segmentation_masks"],"author":"Thomas Capelle","badges":true,"categories":["Pytorch","fastai","cv"],"date":"2021-06-11","description":"How to save the outputs of your model to disk","image":"images/seg.png","output-file":"2021-06-11-save_segmentation_masks.html","title":"Export Segmentation Masks","toc":true},"headingText":"Inference on one image at a time","containsRefs":false,"markdown":"\n\n\n\n![Segmentation](images/seg.png)\n\nYou already have a trained model and want to run inference over a large dataset of images (in my case over 3kk images), how to do this efficiently and fast. We already have access to `fastai`'s `Learner.get_preds` method, but you need to be able to fit  in memory the full output, for my use case of segmentation masks over large images it is just not possible.\nLet's build a solution to save the prediction to file using a dataloader to make inference fast and batched.\n\nwe already have a model that is working good, for the sake of simplicity I am loading a `torchscript` model from file.\n\nwe have a dataframe with our data\n\n\nlet's grab one image:\n\nWe will use fastai transforms, but the same can be done using `torchvision.transforms`, \n```python\nimport torchvision.transforms as T\nimg_tfms = T.Compose([T.ToTensor(),\n                      T.Normalize(*WSISEG_STATS)])\n```\n\nHere to compose we use the `Pipeline`\n\nthese transforms will convert the image to tensor, so we can pass it through the model\n\ninto the model\n\nthis is a segmentation model with 4 classes, so the output has 4 channels. We need to postprocess this to get a 1 channel `uint8` image with values in [0,1,2,3]. We will also reconvert this output to `PIL` to save it later.\n\nit looks fine\n\nNow, if we want to compute this process on all images (it is going to be slow...) let's do some refactor:\n\nWe now want to save this image besides the original one. Let's leverage some `fastcore`'s magic and patch `pathlib.Path` to be able to put an arbitrary suffix on our images:\n:::{.callout-note}\n\n`Path.with_suffix` cannot put an arbitrary suffif with the `_GT` string before the extension, so we have to patch it.\n\n:::\n\nthis way, our masks will be called `*_GT.png`\n\nTo process the full dataset one would do this:\n- iterate over all images one by one\n- compute inference on each\n- save the postprocessed mask\n\n## Batched images to files\n> From DataLoader to files\n\nLet's try to make better use of the GPU, we will feed batches of images all at once. We already have `DataLoaders` to do this, let's make a simple `TfmdDL` object, to stack our items with the transforms together. Here we need to split the transforms on the ones that are called after getting the item (the image path) and after stacking the tensors into a batch. The latter ones are computer on the GPU.\n\nwe get a nice batch of images (64 in this case) ready to feed the model\n\nHere we have performed inference on 64 images all at once, but the posprocessing need to happen imager per image anyway.\nWe have recover the original images filenames to be able to store the masks and make the maping with the original image. We kind of need a DataLoader for the filenames, here comes `chunked` function to the recue.\n:::{.callout-note}\n\n`chunked` splits the files on chunks of `bs` so we can iterate at the same time on the image paths.\n\n:::\n\nIn my case, this solution is 10 times faster than doing the images one by one.\n\n## With a DataBlock\nWe can do the same thing with a data block\n\nthe `DataBlock` API generates a `DataLoaders` object, that is just a wrapper around a train/valid pair of `DataLoaders`. As we passed a dummy split (no split), the `train` dataloader is empty, and we will use only the valid one. Also, the batch in this case is composed of a tuple `(x,y)` where `y` is empty, hence we need to do `x, = b` (or `b[0]`)\n\n## The fastai way\n> Using the `test_dl` on the `Learner`.\n\nIf you have loaded in memory a learner (or a DataLoaders) you can use the `test_dl` method. This is very handful when you just finished training your model. You can easily construct a dataloader with the exact same transforms used to train the model (in reality it takes the validation transforms, so no augment and no shuffling). Then, you can do just like before using the `test_dl`\n","srcMarkdownNoYaml":"\n\n\n\n![Segmentation](images/seg.png)\n\nYou already have a trained model and want to run inference over a large dataset of images (in my case over 3kk images), how to do this efficiently and fast. We already have access to `fastai`'s `Learner.get_preds` method, but you need to be able to fit  in memory the full output, for my use case of segmentation masks over large images it is just not possible.\nLet's build a solution to save the prediction to file using a dataloader to make inference fast and batched.\n\nwe already have a model that is working good, for the sake of simplicity I am loading a `torchscript` model from file.\n\nwe have a dataframe with our data\n\n## Inference on one image at a time\n\nlet's grab one image:\n\nWe will use fastai transforms, but the same can be done using `torchvision.transforms`, \n```python\nimport torchvision.transforms as T\nimg_tfms = T.Compose([T.ToTensor(),\n                      T.Normalize(*WSISEG_STATS)])\n```\n\nHere to compose we use the `Pipeline`\n\nthese transforms will convert the image to tensor, so we can pass it through the model\n\ninto the model\n\nthis is a segmentation model with 4 classes, so the output has 4 channels. We need to postprocess this to get a 1 channel `uint8` image with values in [0,1,2,3]. We will also reconvert this output to `PIL` to save it later.\n\nit looks fine\n\nNow, if we want to compute this process on all images (it is going to be slow...) let's do some refactor:\n\nWe now want to save this image besides the original one. Let's leverage some `fastcore`'s magic and patch `pathlib.Path` to be able to put an arbitrary suffix on our images:\n:::{.callout-note}\n\n`Path.with_suffix` cannot put an arbitrary suffif with the `_GT` string before the extension, so we have to patch it.\n\n:::\n\nthis way, our masks will be called `*_GT.png`\n\nTo process the full dataset one would do this:\n- iterate over all images one by one\n- compute inference on each\n- save the postprocessed mask\n\n## Batched images to files\n> From DataLoader to files\n\nLet's try to make better use of the GPU, we will feed batches of images all at once. We already have `DataLoaders` to do this, let's make a simple `TfmdDL` object, to stack our items with the transforms together. Here we need to split the transforms on the ones that are called after getting the item (the image path) and after stacking the tensors into a batch. The latter ones are computer on the GPU.\n\nwe get a nice batch of images (64 in this case) ready to feed the model\n\nHere we have performed inference on 64 images all at once, but the posprocessing need to happen imager per image anyway.\nWe have recover the original images filenames to be able to store the masks and make the maping with the original image. We kind of need a DataLoader for the filenames, here comes `chunked` function to the recue.\n:::{.callout-note}\n\n`chunked` splits the files on chunks of `bs` so we can iterate at the same time on the image paths.\n\n:::\n\nIn my case, this solution is 10 times faster than doing the images one by one.\n\n## With a DataBlock\nWe can do the same thing with a data block\n\nthe `DataBlock` API generates a `DataLoaders` object, that is just a wrapper around a train/valid pair of `DataLoaders`. As we passed a dummy split (no split), the `train` dataloader is empty, and we will use only the valid one. Also, the batch in this case is composed of a tuple `(x,y)` where `y` is empty, hence we need to do `x, = b` (or `b[0]`)\n\n## The fastai way\n> Using the `test_dl` on the `Learner`.\n\nIf you have loaded in memory a learner (or a DataLoaders) you can use the `test_dl` method. This is very handful when you just finished training your model. You can easily construct a dataloader with the exact same transforms used to train the model (in reality it takes the validation transforms, so no augment and no shuffling). Then, you can do just like before using the `test_dl`\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"output-file":"2021-06-11-save_segmentation_masks.html","toc":true},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.39","theme":"cosmo","title-block-banner":true,"aliases":["/Pytorch/fastai/cv/2021/06/11/save_segmentation_masks"],"author":"Thomas Capelle","badges":true,"categories":["Pytorch","fastai","cv"],"date":"2021-06-11","description":"How to save the outputs of your model to disk","image":"images/seg.png","title":"Export Segmentation Masks"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}